{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header",
            "metadata": {},
            "source": [
                "# CatBoost Model for TDE Classification\n",
                "\n",
                "This notebook trains a CatBoost model with Optuna hyperparameter tuning.\n",
                "\n",
                "**Key Features:**\n",
                "- Uses the same cross-validation folds as all other models\n",
                "- Handles class imbalance with `scale_pos_weight`\n",
                "- Saves OOF and test predictions for ensemble"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import re\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from catboost import CatBoostClassifier\n",
                "import optuna\n",
                "from sklearn.metrics import precision_recall_curve\n",
                "import warnings\n",
                "\n",
                "warnings.filterwarnings('ignore')\n",
                "optuna.logging.set_verbosity(optuna.logging.WARNING)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "N_OPTUNA_TRIALS = 30  # CatBoost is slower, fewer trials\n",
                "RANDOM_STATE = 15\n",
                "MODEL_NAME = 'cat'\n",
                "\n",
                "# Paths\n",
                "DATA_DIR = os.path.join('..', 'data', 'processed')\n",
                "MODEL_DIR = os.path.join('..', 'models')\n",
                "TRAIN_PATH = os.path.join(DATA_DIR, '2dgp_train_features.parquet')\n",
                "TEST_PATH = os.path.join(DATA_DIR, '2dgp_test_features.parquet')\n",
                "FOLDS_PATH = os.path.join(DATA_DIR, 'train_folds.csv')\n",
                "\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "load_data",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading data...\n",
                        "Train shape: (3043, 291)\n",
                        "Test shape: (7135, 289)\n",
                        "Class distribution: {0: 2895, 1: 148}\n"
                    ]
                }
            ],
            "source": [
                "# Load data\n",
                "print(\"Loading data...\")\n",
                "train = pd.read_parquet(TRAIN_PATH)\n",
                "test = pd.read_parquet(TEST_PATH)\n",
                "folds = pd.read_csv(FOLDS_PATH)\n",
                "\n",
                "# Merge folds with training data\n",
                "train = train.merge(folds[['object_id', 'kfold']], on='object_id', how='left')\n",
                "\n",
                "print(f\"Train shape: {train.shape}\")\n",
                "print(f\"Test shape: {test.shape}\")\n",
                "print(f\"Class distribution: {train['target'].value_counts().to_dict()}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "prepare_features",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Feature count: 288\n",
                        "scale_pos_weight: 19.56\n"
                    ]
                }
            ],
            "source": [
                "# Prepare features\n",
                "drop_cols = ['object_id', 'target', 'split', 'SpecType', 'kfold']\n",
                "feature_cols = [c for c in train.columns if c not in drop_cols]\n",
                "\n",
                "X = train[feature_cols].copy()\n",
                "y = train['target']\n",
                "kfold = train['kfold']\n",
                "\n",
                "X_test = test[feature_cols].copy()\n",
                "object_ids_test = test['object_id']\n",
                "\n",
                "# Calculate scale_pos_weight for imbalance\n",
                "scale_pos_weight = (y == 0).sum() / (y == 1).sum()\n",
                "print(f\"Feature count: {len(feature_cols)}\")\n",
                "print(f\"scale_pos_weight: {scale_pos_weight:.2f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "optuna_objective",
            "metadata": {},
            "outputs": [],
            "source": [
                "def objective(trial):\n",
                "    params = {\n",
                "        'iterations': 1000,\n",
                "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.15),\n",
                "        'depth': trial.suggest_int('depth', 3, 6),\n",
                "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1e-3, 10.0, log=True),\n",
                "        'random_strength': trial.suggest_float('random_strength', 1e-3, 10.0, log=True),\n",
                "        'scale_pos_weight': trial.suggest_float('scale_pos_weight', 10, 40),\n",
                "        'eval_metric': 'PRAUC',\n",
                "        'early_stopping_rounds': 50,\n",
                "        'verbose': 0,\n",
                "        'allow_writing_files': False,\n",
                "        'random_seed': RANDOM_STATE\n",
                "    }\n",
                "    \n",
                "    f1_scores = []\n",
                "    for fold in range(5):\n",
                "        train_idx = kfold != fold\n",
                "        val_idx = kfold == fold\n",
                "        \n",
                "        X_tr, X_val = X[train_idx], X[val_idx]\n",
                "        y_tr, y_val = y[train_idx], y[val_idx]\n",
                "        \n",
                "        clf = CatBoostClassifier(**params)\n",
                "        clf.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
                "        \n",
                "        preds = clf.predict_proba(X_val)[:, 1]\n",
                "        prec, rec, _ = precision_recall_curve(y_val, preds)\n",
                "        f1 = 2 * (prec * rec) / (prec + rec + 1e-9)\n",
                "        f1_scores.append(np.max(f1))\n",
                "    \n",
                "    return np.mean(f1_scores)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "run_optuna",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Running Optuna with 30 trials...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "de246245c32347f7a411336e3ad4dc39",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "  0%|          | 0/30 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Best F1 Score: 0.6081\n",
                        "Best params: {'learning_rate': 0.030962546779134854, 'depth': 4, 'l2_leaf_reg': 0.7418556543816056, 'random_strength': 0.22720577533754555, 'scale_pos_weight': 14.024393649955671}\n"
                    ]
                }
            ],
            "source": [
                "# Run Optuna optimization\n",
                "print(f\"Running Optuna with {N_OPTUNA_TRIALS} trials...\")\n",
                "study = optuna.create_study(direction='maximize')\n",
                "study.optimize(objective, n_trials=N_OPTUNA_TRIALS, show_progress_bar=True)\n",
                "\n",
                "print(f\"\\nBest F1 Score: {study.best_value:.4f}\")\n",
                "print(f\"Best params: {study.best_params}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "train_final",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Training final model with best params...\n",
                        "Fold 0 complete.\n",
                        "Fold 1 complete.\n",
                        "Fold 2 complete.\n",
                        "Fold 3 complete.\n",
                        "Fold 4 complete.\n",
                        "\n",
                        "OOF F1 Score: 0.5570 at threshold 0.5666\n"
                    ]
                }
            ],
            "source": [
                "# Train final model with best params\n",
                "print(\"\\nTraining final model with best params...\")\n",
                "\n",
                "best_params = study.best_params.copy()\n",
                "best_params.update({\n",
                "    'iterations': 3000,\n",
                "    'eval_metric': 'PRAUC',\n",
                "    'early_stopping_rounds': 150,\n",
                "    'verbose': 0,\n",
                "    'allow_writing_files': False,\n",
                "    'random_seed': RANDOM_STATE\n",
                "})\n",
                "\n",
                "oof_preds = np.zeros(len(y))\n",
                "test_preds = np.zeros(len(X_test))\n",
                "\n",
                "for fold in range(5):\n",
                "    train_idx = kfold != fold\n",
                "    val_idx = kfold == fold\n",
                "    \n",
                "    X_tr, X_val = X[train_idx], X[val_idx]\n",
                "    y_tr, y_val = y[train_idx], y[val_idx]\n",
                "    \n",
                "    clf = CatBoostClassifier(**best_params)\n",
                "    clf.fit(X_tr, y_tr, eval_set=(X_val, y_val))\n",
                "    \n",
                "    oof_preds[val_idx] = clf.predict_proba(X_val)[:, 1]\n",
                "    test_preds += clf.predict_proba(X_test)[:, 1] / 5\n",
                "    \n",
                "    print(f\"Fold {fold} complete.\")\n",
                "\n",
                "# Calculate final OOF F1\n",
                "prec, rec, thresh = precision_recall_curve(y, oof_preds)\n",
                "f1 = 2 * (prec[:-1] * rec[:-1]) / (prec[:-1] + rec[:-1] + 1e-9)\n",
                "best_thresh = thresh[np.argmax(f1)]\n",
                "print(f\"\\nOOF F1 Score: {np.max(f1):.4f} at threshold {best_thresh:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "save_predictions",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Saved OOF predictions to: models/oof_cat.csv\n",
                        "Saved test predictions to: models/preds_cat.csv\n"
                    ]
                }
            ],
            "source": [
                "# Save predictions\n",
                "oof_df = pd.DataFrame({\n",
                "    'object_id': train['object_id'],\n",
                "    'target': y,\n",
                "    f'pred_{MODEL_NAME}': oof_preds\n",
                "})\n",
                "oof_df.to_csv(os.path.join(MODEL_DIR, f'oof_{MODEL_NAME}.csv'), index=False)\n",
                "\n",
                "test_df = pd.DataFrame({\n",
                "    'object_id': object_ids_test,\n",
                "    f'pred_{MODEL_NAME}': test_preds\n",
                "})\n",
                "test_df.to_csv(os.path.join(MODEL_DIR, f'preds_{MODEL_NAME}.csv'), index=False)\n",
                "\n",
                "print(f\"\\nSaved OOF predictions to: models/oof_{MODEL_NAME}.csv\")\n",
                "print(f\"Saved test predictions to: models/preds_{MODEL_NAME}.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "MLFinal",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.14"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
