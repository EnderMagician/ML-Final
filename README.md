# ðŸŒŒ MALLORN Astronomical Classification Challenge

**Goal:** Identify rare Tidal Disruption Events (TDEs)â€”stars being torn apart by black holesâ€”from photometric light curves.

**Competition:** [Kaggle Competition Link](https://www.kaggle.com/competitions/mallorn-astronomical-classification-challenge)

**Data Source:** Zwicky Transient Facility (ZTF) simulations for LSST.

## ðŸ›  Prerequisites (Read First)

You must have **Conda** or **Miniconda** installed to run this project.

This project uses a locked `environment.yml` to manage complex astronomy dependencies (like `sncosmo` and `astropy`) that often fail with standard pip installs.

ðŸ‘‰ [Download Miniconda Here](https://docs.conda.io/en/latest/miniconda.html) if you don't have it.

## ðŸš€ Quick Start

### 1. Set up the Environment

Open your terminal in this folder and run the following commands:

```bash
# 1. Update/Create the environment from the file
conda env update --file environment.yml --prune

# 2. Activate the environment
conda activate MLFinal
```

### 2. Authenticate Kaggle

Ensure your API key is in the default location so the scripts can download data automatically.

* **Windows:** `C:\Users\<Username>\.kaggle\kaggle.json`
* **Linux/Mac:** `~/.kaggle/kaggle.json`

### 3. Get the Data

Run the first exploration notebook. It includes a script to auto-download and unzip the data into the correct folder.

1. Open `notebooks/01_exploration.ipynb`
2. Run the **"Setup"** cell at the top.

## ðŸ“‚ Project Structure

```text
MALLORN_Challenge/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             # Original Kaggle CSVs (Do not edit these!)
â”‚   â””â”€â”€ processed/       # Cleaned parquet/csv files generated by notebooks
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ oof_*.csv        # Out-of-fold predictions for each model
â”‚   â””â”€â”€ preds_*.csv      # Test set predictions for each model
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploration.ipynb       # Visualization & Data Download
â”‚   â”œâ”€â”€ 02_preprocessing_nn.ipynb  # NN-specific Feature Engineering
â”‚   â”œâ”€â”€ 03_make_folds.ipynb        # StratifiedKFold Cross-Validation Setup
â”‚   â”œâ”€â”€ 04_XGBoost.ipynb           # XGBoost Training with Optuna
â”‚   â”œâ”€â”€ 04_LightGBM.ipynb          # LightGBM Training with Optuna
â”‚   â”œâ”€â”€ 04_CatBoost.ipynb          # CatBoost Training with Optuna
â”‚   â”œâ”€â”€ 04_ResNet.ipynb            # ResNet Neural Network Training
â”‚   â”œâ”€â”€ 05_ensemble.ipynb          # Model Ensembling & Final Submission
â”‚   â”œâ”€â”€ catboost.ipynb             # CatBoost Experimentation
â”‚   â””â”€â”€ data-process-mallorn.ipynb # Data Processing Utilities
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py      # Makes this folder importable
â”‚   â””â”€â”€ plotting.py      # Helper functions for plotting light curves
â”‚
â”œâ”€â”€ submissions/         # Final submission files
â”œâ”€â”€ environment.yml      # The exact recipe for the Python environment
â””â”€â”€ README.md            # This file
```

## ðŸ“Š Key Libraries Used

* **`sncosmo`**: For supernova/transient light curve analysis.
* **`astropy`**: For astronomical coordinates and time (MJD) conversions.
* **`xgboost` / `lightgbm` / `catboost`**: For gradient boosting classification models.
* **`pytorch`**: For the ResNet neural network model.
* **`optuna`**: For hyperparameter optimization across all models.
* **`imbalanced-learn`**: To handle the rarity of TDEs.
